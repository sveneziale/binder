{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning example\n",
    "\n",
    "In this notebook we explore a classical machine learning approach to a classification problem using a unsupervised learning approach and an algorithm called [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering). We will use the library [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "In this example we will use the `iris dataset` ([link to the dataset card](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)). \n",
    "This dataset is already included in the scikit-learn library, so we do not need to do any preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = len(iris['data'])\n",
    "n_features = len(iris['feature_names'])\n",
    "feature_names = iris['feature_names']\n",
    "targets = iris['target_names']\n",
    "print(f'The dataset has {n_data_points} datapoints')\n",
    "print(f'The data has {n_features} features, they are {feature_names}')\n",
    "print(f'The data can have targets {targets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only two features (sepal length and sepal width), so that we can plot the datapoints in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plotting code (the different colours correspond to different classes)\n",
    "_, ax = plt.subplots()\n",
    "X0 = [x[0] for x in X]\n",
    "X1 = [x[1] for x in X]\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us divide into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True) # You can change the test_size to use more or less data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans is an unsupervised learning algorithm, which means that it can be applied to data which is unlabelled. In our case (for the iris dataset) we have labels, and we know that each datapoint belongs to one of three classes. However, in a usual application of unsupervised learning we would not know that, so part of the process is figuring out how many clusters are best for our task. \n",
    "\n",
    "The way that KMeans achieves this is as follows. Given a number of clusters $N$ the algorithm tries to divide the dataset in $N$ clusters such that they minimise a quantity called *inertia*. This intuitively measures how cohesive each cluster is.\n",
    "\n",
    "There are different ways of choosing the number of clusters: one such method is the [ELBOW method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)), which finds a good trade-off between number of clusters and inertia. \n",
    "\n",
    "Let's fit different KMeans models for different number of clusters and compute their inertia. Then let's plot one against the other to figure out how many clusters we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a range of possible number of clusters\n",
    "N_clusters = range(1,21)\n",
    "\n",
    "# Set somewhere to store the inertia\n",
    "inertias = []\n",
    "\n",
    "# Loop over the possible number of clusters and compute the inertia for the corresponding model\n",
    "for N in N_clusters:\n",
    "    # Define model\n",
    "    clf = KMeans(n_clusters=N)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # Compute and store the inertia\n",
    "    inertias.append(clf.inertia_)\n",
    "\n",
    "# Plot number of clusters against inertia\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.plot(N_clusters, inertias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As many things in machine learning this is more of a heuristic than a precise method. In fact, it is hard to see from the graph above why three clusters should be the correct answer! Nevertheless, since we know we have three clusters, let's carry out with $N=3$.\n",
    "\n",
    "Let us fit the KMeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters=3)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not a supervised method, so calculating accuracy makes less sense than when we looked at the SVM. Instead, we plot the areas that are divided into clusters by the KMeans model and compare it to our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some boring plotting code\n",
    "_, ax = plt.subplots()\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "\n",
    "# Plot the decision boundaries\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X_test,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    xlabel=iris.feature_names[0],\n",
    "    ylabel=iris.feature_names[1],\n",
    "    shading=\"auto\",\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Scatter the data\n",
    "scatter = ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "disp.ax_.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    iris.target_names,\n",
    "    loc=\"lower left\",\n",
    "    title=\"Classes\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to try\n",
    "- What would the final plot look like for different number of clusters?\n",
    "- There are different metrics for clustering (e.g. silhouette score). Read about them [here](https://scikit-learn.org/1.5/modules/clustering.html#clustering-evaluation) and choose one to evaluate the final model on.\n",
    "- We have used the first two columns of the dataset. What happens if we use the last two? Or any other two?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagepytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
