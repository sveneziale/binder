{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning example\n",
    "\n",
    "In this example we will use the `iris dataset` ([link to the dataset card](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)).\n",
    "\n",
    "This dataset is already included in the sklearn library, so we do not need to do any preprocessing.\n",
    "\n",
    "We train a classifier in an unsupervised fashion using the [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    " \n",
    "# Import the dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = len(iris['data'])\n",
    "n_features = len(iris['feature_names'])\n",
    "feature_names = iris['feature_names']\n",
    "targets = iris['target_names']\n",
    "print(f'The dataset has {n_data_points} datapoints')\n",
    "print(f'The data has {n_features} features, they are {feature_names}')\n",
    "print(f'The data can have targets {targets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider only two features (sepal length and sepal width), so that we can plot the datapoints in the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us divide into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans is an unsupervised learning algorithm, which means that it can be applied to data which is unlabelled. In our case (for the iris dataset) we have labels, and we know that each datapoint belongs to one of three classes. However, in a usual application of unsupervised learning we would not know that, so part of the process is figuring out how many clusters are best for our task. \n",
    "\n",
    "The way that KMeans achieves this is as follows. Given a number of clusters $N$ the algorithm tries to divide the dataset in $N$ clusters such that they minimise a quantity called inertia. This intuitively measures how cohesive each cluster is.\n",
    "\n",
    "There are different ways of choosing the number of clusters: one such method is the [ELBOW method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)), which finds a good trade-off between number of clusters and inertia. \n",
    "\n",
    "Let's fit different KMeans models for different number of clusters and compute their inertia. Then let's plot one against the other to figure out how many clusters we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_clusters = range(1,21)\n",
    "inertias = []\n",
    "\n",
    "for N in N_clusters:\n",
    "    # Define model\n",
    "    clf = KMeans(n_clusters=N)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # Compute and store the inertia\n",
    "    inertias.append(clf.inertia_)\n",
    "\n",
    "# Plot number of clusters against inertia\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.plot(N_clusters, inertias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As many things in machine learning this is more of a heuristic than a precise method. In fact it is hard to see from the graph above why 3 clusters should be the correct answer! Nevertheless, since we know we have three clusters, let's carry out with $N=3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit the KMeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(n_clusters=3)\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not a supervised method, so calculating accuracy makes less sense than when we looked at the SVM. Instead, we plot the areas that are divided into clusters by the KMeans model and compare it to our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Just some boring plotting code\n",
    "_, ax = plt.subplots()\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X_test,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    xlabel=iris.feature_names[0],\n",
    "    ylabel=iris.feature_names[1],\n",
    "    shading=\"auto\",\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "scatter = ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "disp.ax_.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    iris.target_names,\n",
    "    loc=\"lower left\",\n",
    "    title=\"Classes\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to try\n",
    "- What would the final plot look like for different number of clusters?\n",
    "- There are different metrics for clustering (e.g. silhouette score). Read about them [here](https://scikit-learn.org/1.5/modules/clustering.html#clustering-evaluation) and choose one to evaluate the final model on.\n",
    "- We have used the first two columns of the dataset. What happens if we use the last two? Or any other two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagepytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
